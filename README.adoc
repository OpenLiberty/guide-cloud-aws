//
// Copyright (c) 2019 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:projectid: cloud-aws
:page-layout: guide-multipane
:page-duration: 45 minutes
:page-releasedate: 2019-04-01
:page-description: Explore how to deploy microservices to Amazon Elastic Container Service for Kubernetes and manage your cluster.
:page-tags: ['Kubernetes', 'Docker']
:page-permalink: /guides/{projectid}
:page-related-guides: ['kubernetes-intro']
:common-includes: https://raw.githubusercontent.com/OpenLiberty/guides-common/master
:source-highlighter: prettify
:page-seo-title: Amazon Elastic Container Service (EKS) tutorial
:page-seo-description: How to deploy microservices to Amazon EKS
:guide-author: Open Liberty
= Deploying microservices to Amazon Elastic Container Service for Kubernetes

[.hidden]
NOTE: This repository contains the guide documentation source. To view the guide in published form, view it on the https://openliberty.io/guides/{projectid}.html[Open Liberty website^].
 
Explore how to push Docker images to a Amazon Elastic Container Registry and run them inside of containers on Amazon Elastic Container Service for Kubernetes.

:kube: Kubernetes
:hashtag: #
:win: WINDOWS
:mac: MAC
:linux: LINUX
:system-api: http://[hostname]:31000/system/properties
:inventory-api: http://[hostname]:32000/inventory/systems

// =================================================================================================
// What is {kube}
// =================================================================================================

== Why use Kubernetes services in the cloud?

Single node {kube} clusters such as Minikube and Docker Desktop are great for testing your 
microservices locally, but ultimately you will want a system that can handle production workloads. 
Various clouds offer solutions for running your workloads in a {kube} cluster. Using a 
cloud-based infrastructure allows you to focus on developing your microservices rather than 
worrying about details that are related to the servers you deploy them to. Using cloud allows
you to more easily scale your microservices and serve them in a high-availability setup.

// =================================================================================================
// Introduction
// =================================================================================================

== What you'll learn

You will learn how to deploy two microservices in Open Liberty containers to a {kube}
cluster on Amazon Elastic Container Service for Kubernetes (EKS). Amazon Web Services (AWS) 
offers a managed Kubernetes service called Amazon EKS. EKS simplifies the process of running 
Kubernetes on AWS without needing to install or maintain your own Kubernetes control plane. 
It provides a hosted {kube} cluster that you can deploy your microservices to. You will 
use it in conjunction with Amazon Elastic Container Registry (ECR).

The two microservices you will deploy are called `system` and `inventory`. The `system` microservice
returns the JVM system properties of the running container and it returns the pod's name in the HTTP header
making replicas easy to distinguish from each other. The `inventory` microservice
adds the properties from the `system` microservice to the inventory. This demonstrates
how communication can be established between pods inside a cluster.

// =================================================================================================
// Prerequisites
// =================================================================================================

== Prerequisites

Before you begin, have the following tools installed:

- *Docker:* You will need a containerization software for building containers. Kubernetes 
supports various container types. You will use Docker in this guide. For installation 
instructions, refer to the official https://docs.docker.com/install/[Docker^] documentation.

- *kubectl:* You will need the Kubernetes command-line tool `kubectl` to interact with your 
Kubernetes cluster. See the official https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl[Install and Set Up kubectl^]
documentation for downloading and setting up `kubectl` on your platform.

- *IAM Authenticator:* To allow IAM authentication for your Amazon EKS cluster, you must install the AWS
IAM Authenticator for Kubernetes. Follow the https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html[Installing aws-iam-authenticator^]
instructions for installing on your platform. 

- *eksctl:* In this guide, we will use the `eksctl` CLI tool for provisioning your EKS cluster. 
Navigate to the https://github.com/weaveworks/eksctl/releases[eksctl releases page^] and 
download the latest stable release. Extract the archive and add the directory with the 
extracted files to your path.

- *AWS CLI:* Throughout this guide, you will need to use the AWS Command Line Interface (CLI). To install
the AWS CLI, you must have Python installed. See the https://www.python.org/downloads/[Downloading Python^] 
documentation for downloading the latest version of Python.

Once you have Python installed, install the AWS CLI by following the official
https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html[Installing the AWS CLI^]
documentation. 

To verify that the AWS CLI is installed correctly, run the following command.

[role=command]
```
aws --version
```

Once the AWS CLI is installed, it must be configured by running the AWS configure command. 
Before configuring the AWS CLI, you will need to create an AWS Identity and Access Management (IAM)
user. Navigate to the https://console.aws.amazon.com/iam/home#/users[Identity and Access Management^]
users dashboard and create a user through the UI. While creating a user, you must give the 
user `programmatic access` when selecting the AWS access type. You will also be prompted
to add the user to a group, a group allows you to specify permissions for multiple users. 
If you do not have an existing group, you need to create a new one. Be sure to take note
of the `Access Key ID` and `Secret Access Key`.

[role=command]
```
aws configure
```

You will be prompted for several pieces of information, including an `AWS access` key 
and an `AWS secret access` key. These keys are associated with the AWS Identity and Access
Management (IAM) user you created earlier.

Next, you will be prompted to enter a region, which will be the servers that your 
requests get sent to. Select the region that is closest to you. For a full list of regions, 
see the https://docs.aws.amazon.com/general/latest/gr/rande.html#eks_region[AWS Regions and Endpoints^].

Finally, when prompted to enter the output format, enter `json`. 

After you are done filling out the various pieces of information, the settings will be 
stored in the default profile. Anytime you run an AWS CLI command without specifying 
a profile, the default profile will be used. 


// =================================================================================================
// Getting Started
// =================================================================================================

[role=command]
include::{common-includes}/gitclone.adoc[]

// no "try what you'll build" section in this guide since it would be too long due to all setup the user will have to do.

== Deploying microservices to Amazon Elastic Container Service for Kubernetes (EKS)

In this section, you will learn how to deploy two microservices in Open Liberty containers to a {kube}
cluster on EKS. After provisioning a {kube} cluster, you will build and containerize 
the `system` and `inventory` microservices, push them to a Docker registry and then deploy
them to your {kube} cluster. 

=== Provisioning a cluster

In this guide, we use `eksctl` to create the Kubernetes cluster on EKS. The `eksctl`
CLI tool greatly simplifies the process of creating clusters on EKS. To create your 
cluster, use the `eksctl create cluster` command.

[role=command]
```
eksctl create cluster --name=guide-cluster --nodes=1 --node-type=t2.small
```

This creates a cluster that is called `guide-cluster` that uses a single `t2.small` Amazon
Elastic Compute Cloud (EC2) instance as the worker node. When the cluster is created, 
you will see an output similar to the following.

[source, role="no_copy"]
```
[âœ”]  EKS cluster "guide-cluster" in "us-east-2" region is ready
```

Once your cluster is ready, EKS connects `kubectl` to the cluster.
Verify that you're connected to the cluster by checking the cluster's nodes.

[role=command]
```
kubectl get nodes
```

[source, role="no_copy"]
----
NAME                            STATUS    ROLES     AGE       VERSION
ip.us-east-2.compute.internal   Ready     <none>    7m        v1.11.5
----

// =================================================================================================
// Building and containerizing the microservices
// =================================================================================================

=== Building and containerizing the microservices

The first step of deploying to {kube} is to build your microservices and containerize them with Docker.

The starting Java project, which you can find in the `start` directory, is a multi-module Maven
project. It's made up of the `system` and `inventory` microservices. Each microservice resides in its own directory,
`start/system` and `start/inventory`. Each of these directories also contains a Dockerfile, which is necessary
for building Docker images. If you're unfamiliar with Dockerfiles, check out the
https://openliberty.io/guides/docker.html[Using Docker containers to develop microservices^] guide.
It covers Dockerfiles in depth.

If you're familiar with Maven and Docker, you might be tempted to run a Maven build first and then
use the `.war` file to build a Docker image. We've setup the projects such that this process is automated
as a part of a single Maven build. It's created by using the `dockerfile-maven` plug-in. The plug-in automatically
picks up the Dockerfile located in the same directory as its POM file and builds a Docker image from it.

****
[system]#*{win}*#

On the Docker Desktop General Setting page, ensure that the option Expose daemon on 
tcp://localhost:2375 without TLS is enabled. This configuration is required by the `dockerfile-maven` 
part of the build.

****

Navigate to the `start` directory and run the following command:

[role=command]
```
mvn package
```

The `package` goal automatically starts the `dockerfile-maven:build` goal. It runs during the
`package` phase. This goal builds a Docker image from the Dockerfile located in the same directory
as the POM file.

During the build, you'll see various Docker messages describing what images are being downloaded and
built. When the build finishes, run the following command to list all local Docker images:

[role=command]
```
docker images
```

Verify that the `system:1.0-SNAPSHOT` and `inventory:1.0-SNAPSHOT` images are listed among them, for example:

[source, role="no_copy"]
----
REPOSITORY                    TAG
system                        1.0-SNAPSHOT
inventory                     1.0-SNAPSHOT
open-liberty                  latest
----

If you don't see the `system:1.0-SNAPSHOT` and `inventory:1.0-SNAPSHOT` images, then check the Maven
build log for any potential errors.

// =================================================================================================
// Pushing the images to a docker registry
// =================================================================================================

=== Pushing the images to a Docker registry

Pushing the images to a registry allows the cluster to create pods using your Docker images. 
The registry that you will use is called Amazon Elastic Container Registry (ECR).

First, we must authenticate your Docker client to your ECR registry. Start by running the
`get-login` command.
[role=command]
```
aws ecr get-login --no-include-email
```

If you see `Unknown options: --no-include-email`, update your AWS CLI to the latest version. 
The `get-login` command returns a `docker login` command similar to the following.
[source, role="no_copy"]
```
docker login -u AWS -p [password_string] https://[aws_account_id].dkr.ecr.[region].amazonaws.com
```

Run the `docker login` command that is returned to finish authenticating your Docker client.

Next, make a repository to store the `system` and `inventory` images, respectively.
[role=command]
```
aws ecr create-repository --repository-name awsguide/system
aws ecr create-repository --repository-name awsguide/inventory
```

You will see an output similar to the following.

[source, role="no_copy"]
```
{
    "repository": {
        "registryId": "[aws_account_id]",
        "repositoryName": "awsguide/system",
        "repositoryArn": "arn:aws:ecr:us-east-2:[aws_account_id]:repository/awsguide/system",
        "createdAt": 1553111916.0,
        "repositoryUri": "[aws_account_id].ecr.us-east-2.amazonaws.com/awsguide/system"
    }
}
```

Take note of the repository URI for both the `system` and `inventory` repository as you will need 
them when tagging and pushing your images.

// Tagging images
Next, you need to tag your Docker images with the relevant data about your registry. 

[source, role="no_copy"]
```
docker tag system:1.0-SNAPSHOT [system-repository-uri]:1.0-SNAPSHOT
docker tag inventory:1.0-SNAPSHOT [inventory-repository-uri]:1.0-SNAPSHOT
```

// Pushing images
Finally, push your images to the registry.

[source, role="no_copy"]
```
docker push [system-repository-uri]:1.0-SNAPSHOT
docker push [inventory-repository-uri]:1.0-SNAPSHOT
```

When tagging and pushing your images, remember to substitute `[system-repository-uri]` and 
`[inventory-repository-uri]` with the appropriate URI for the system and inventory repositories. 

// =================================================================================================
// Deploying the microservices
// =================================================================================================

=== Deploying the microservices

Now that your Docker images are built, deploy them using a Kubernetes resource definition.

A Kubernetes resource definition is a yaml file that contains a description of all your 
deployments, services, or any other resources that you want to deploy. All resources can 
also be deleted from the cluster by using the same yaml file that you used to deploy them.
The `kubernetes.yaml` resource definition file is provided for you. If you are interested 
in learning more about the Kubernetes resource definition, check out the 
https://openliberty.io/guides/kubernetes-intro.html[Deploying microservices to Kubernetes^]
guide.

[role="code_command hotspot", subs="quotes"]
----
#Update the `kubernetes.yaml` file.#
`kubernetes.yaml`
----

kubernetes.yaml
[source, yaml, linenums, role='code_column']
----
include::finish/kubernetes.yaml[tags=**]
----
[role="edit_command_text"]
The [hotspot=18 hotspot=39]`image` is the name and tag of the docker image that you want 
to use for the container. Update the system [hotspot=18]`image` and the inventory [hotspot=39]`image` 
fields to point to your `system` and `inventory` repository URI, respectively.


Run the following commands to deploy the resources as defined in kubernetes.yaml:
[role='command']
```
kubectl apply -f kubernetes.yaml
```

When the apps are deployed, run the following command to check the status of your pods:
[role='command']
```
kubectl get pods
```

You'll see an output similar to the following if all the pods are healthy and running:

[source, role="no_copy"]
----
NAME                                    READY     STATUS    RESTARTS   AGE
system-deployment-6bd97d9bf6-4ccds      1/1       Running   0          15s
inventory-deployment-645767664f-nbtd9   1/1       Running   0          15s
----

=== Making requests to the microservices

Take note of the `EXTERNAL-IP` in the output of the following command. This is the 
hostname you will substitute into commands later in the guide. 
[role=command]
```
kubectl get nodes -o wide
```

Before we can make a request to `EXTERNAL-IP:31000` or `EXTERNAL-IP:32000`, we must modify
the security group to allow incoming traffic through ports `31000` and `32000`. To get the 
`group-id` of the security group, use the `aws ec2 describe-security-groups` command.
[role=command]
```
aws ec2 describe-security-groups --filters Name=group-name,Values="*eksctl-guide-cluster-nodegroup*"  --query "SecurityGroups[*].{Name:GroupName,ID:GroupId}"
```

Then, add the following rules to the security group to allow incoming traffic through ports
`31000` and `32000`. Don't forget to substitute `[security-group-id]` for the `ID` in the
output of the previous command.
[source, role="no_copy"]
```
aws ec2 authorize-security-group-ingress --protocol tcp --port 31000 --group-id [security-group-id] --cidr 0.0.0.0/0
aws ec2 authorize-security-group-ingress --protocol tcp --port 32000 --group-id [security-group-id] --cidr 0.0.0.0/0
```

After you are finished adding the inbound rules to the security group, you might need to 
wait a few minutes before trying to access the `system` and `inventory` microservices.

Then `curl` or visit the following URLs to access your microservices, substituting the 
appropriate hostname:

- `{system-api}`
- `{inventory-api}/system-service`

The first URL returns system properties and the name of the pod in an HTTP header called `X-Pod-Name`.
To view the header, you can use the `-I` option in the `curl` when making a request to `{system-api}`.
The second URL adds properties from `system-service` to the inventory.
{kube} Service. Visiting `{inventory-api}/[kube-service]` in general adds to the inventory
depending on whether `kube-service` is a valid {kube} Service that can be accessed.

// =================================================================================================
// Testing microservices that are running on AWS EKS
// =================================================================================================

== Testing microservices that are running on AWS EKS

pom.xml
[source, xml, linenums, role='code_column']
----
include::finish/pom.xml[tags=**]
----

A few tests are included for you to test the basic functionality of the microservices. If a test failure
occurs, then you might have introduced a bug into the code. To run the tests, wait for all pods to be
in the ready state before proceeding further. The default properties that are defined in the [hotspot]`pom.xml` are:

[cols="15, 100", options="header"]
|===
| *Property*                      | *Description*
| [hotspot=35]`cluster.ip`        | IP or hostname for your cluster
| [hotspot=36]`system.kube.service` | Name of the {kube} Service wrapping the `system` pods, `system-service` by default.
| [hotspot=37]`system.node.port`    | The NodePort of the {kube} Service `system-service`, 31000 by default.
| [hotspot=38]`inventory.node.port`    | The NodePort of the {kube} Service `inventory-service`, 32000 by default.
|===

Use the following command to run the integration tests against your cluster. Substitute 
`[hostname]` with the appropriate value.

[source, role="no_copy"]
```
mvn verify -Ddockerfile.skip=true -Dcluster.ip=[hostname]
```

The `dockerfile.skip` parameter is set to `true` in order to skip building a new Docker image.

If the tests pass, you'll see an output similar to the following for each service respectively:

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.system.SystemEndpointTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.673 sec - in it.io.openliberty.guides.system.SystemEndpointTest

Results:

Tests run: 2, Failures: 0, Errors: 0, Skipped: 0
----

[source, role="no_copy"]
----
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running it.io.openliberty.guides.inventory.InventoryEndpointTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.222 sec - in it.io.openliberty.guides.inventory.InventoryEndpointTest

Results:

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
----

=== Deploying new version of system microservice

Optionally, you might want to learn how to redeploy a microservice. In this section, you 
will bump the version of the `system` microservice to `2.0-SNAPSHOT` and redeploy
the new version of the microservice.

The tag for the Docker image is dependent on the version specified in the pom.xml file. 
Use the following Maven command to bump the version of the microservice to `2.0-SNAPSHOT`.

[role=command]
```
mvn versions:set -DnewVersion=2.0-SNAPSHOT
```

Use Maven to repackage your microservice and build the new version of the Docker container.

[role=command]
```
mvn package
```

Since you built a new image, it must be pushed to the `awsguide/system` repository
of your container registry again.

// Tagging images
Tag your Docker image with the relevant data about your registry.

[source, role="no_copy"]
```
docker tag system:2.0-SNAPSHOT [system-repository-uri]:2.0-SNAPSHOT
```

// Pushing images
Push your image to the registry.

[source, role="no_copy"]
```
docker push [system-repository-uri]:2.0-SNAPSHOT
```

Update the `system-deployment` deployment to use the new container image that we just
pushed to the registry.
[source, role="no_copy"]
```
kubectl set image deployment/system-deployment system-container=[system-repository-uri]:2.0-SNAPSHOT
```

Use the following command to find the name of the pod running the `system` microservice.

[role=command]
```
kubectl get pods
```

[source, role="no_copy"]
----
NAME                                   READY     STATUS    RESTARTS   AGE
inventory-deployment-6fd959cc4-rf2m2   1/1       Running   0          7m
system-deployment-677b9f5d9c-nqzcf     1/1       Running   0          7m
----

Observe that in this case the `system` microservice is running in the pod called 
`system-deployment-677b9f5d9c-nqzcf`. Substitute the name of your pod into the 
following command to see more details about the pod.

[source, role="no_copy"]
```
kubectl describe pod [pod-name]
```

View the events at the bottom of the command's output. Observe that the pod is using the 
new Docker image `system:2.0-SNAPSHOT`.

[source, role="no_copy"]
----
Events:
  Type    Reason     Age   From                                    Message
  ----    ------     ----  ----                                    -------
  Normal  Scheduled  1m    default-scheduler                       Successfully assigned default/system-deployment-dd44895f6-wmlkm to ip.us-east-2.compute.internal
  Normal  Pulling    1m    kubelet, ip.us-east-2.compute.internal  pulling image "[aws_account_id].dkr.ecr.us-east-2.amazonaws.com/awsguide/system:2.0-SNAPSHOT"
  Normal  Pulled     1m    kubelet, ip.us-east-2.compute.internal  Successfully pulled image "[aws_account_id].dkr.ecr.us-east-2.amazonaws.com/awsguide/system:2.0-SNAPSHOT"
  Normal  Created    1m    kubelet, ip.us-east-2.compute.internal  Created container
  Normal  Started    1m    kubelet, ip.us-east-2.compute.internal  Started container
----

// =================================================================================================
// Tear Down
// =================================================================================================

== Tearing down the environment

When you no longer need your deployed microservices, you can delete all {kube} resources 
by running the `kubectl delete` command:
[role='command']
```
kubectl delete -f kubernetes.yaml
```

Delete the ECR repositories used to store the `system` and `inventory` images.
[role=command]
```
aws ecr delete-repository --repository-name awsguide/system
aws ecr delete-repository --repository-name awsguide/inventory
```

Remove your EKS cluster.
[role=command]
```
eksctl delete cluster --name guide-cluster
```


// =================================================================================================
// finish
// =================================================================================================

== Great work! You're done!

You have just deployed two microservices running in Open Liberty to AWS EKS. You have 
learned how to use `kubectl` to deploy your microservices on a {kube} cluster.

// Multipane
include::{common-includes}/attribution.adoc[subs="attributes"]

// DO NO CREATE ANYMORE SECTIONS AT THIS POINT
// Related guides will be added in automatically here if you included them in ":page-related-guides"